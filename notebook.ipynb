{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from urllib import request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TensorFlow Lite interpreter with the specified model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"model_2024_hairstyle.tflite\")\n",
    "# Allocate tensors for the interpreter\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output details from the interpreter\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input details: [{'name': 'serving_default_input_layer:0', 'index': 0, 'shape': array([  1, 200, 200,   3], dtype=int32), 'shape_signature': array([ -1, 200, 200,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "Output details: [{'name': 'StatefulPartitionedCall_1:0', 'index': 13, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([-1,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "# Print input and output details \n",
    "print(\"Input details:\", input_details) \n",
    "print(\"Output details:\", output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input and output tensor indices from the interpreter details\n",
    "input_index = input_details[0]['index']\n",
    "output_index = output_details[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input index :  0\n",
      "Output index :  13\n"
     ]
    }
   ],
   "source": [
    "# Print the input and output tensor indices\n",
    "print(\"Input index : \", input_index)\n",
    "print(\"Output index : \", output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download an image from a URL\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()  # Read the response into a buffer\n",
    "    stream = BytesIO(buffer)  # Create a BytesIO stream from the buffer\n",
    "    img = Image.open(stream)  # Open the image from the stream\n",
    "    return img\n",
    "\n",
    "# Function to prepare an image by converting it to RGB and resizing it\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')  # Convert image to RGB if not already in that mode\n",
    "    img = img.resize(target_size, Image.NEAREST)  # Resize the image to the target size\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://habrastorage.org/webt/yf/_d/ok/yf_dokzqy3vcritme8ggnzqlvwa.jpeg\" \n",
    "\n",
    "img = download_image(url)  # Download the image from the URL\n",
    "target_size = (200, 200) \n",
    "resized_img = prepare_image(img, target_size) \n",
    "resized_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an image to a numpy array\n",
    "def image_to_array(img):\n",
    "    return np.array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    # Check if the image is in RGB mode, if not convert it to RGB\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    \n",
    "    # Convert the image to a numpy array with float32 data type\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    \n",
    "    # Normalize the pixel values to the range [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "    \n",
    "    return img_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the image\n",
    "preprocessed_img = preprocess_image(resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of the first pixel, R channel  0.23921569\n"
     ]
    }
   ],
   "source": [
    "# extract the R channel of the first pixel\n",
    "first_pixel_r = preprocessed_img[0, 0 ,0]\n",
    "print(\"value of the first pixel, R channel \", first_pixel_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the input tensor\n",
    "interpreter.set_tensor(input_index, [preprocessed_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: [[0.8937725]]\n"
     ]
    }
   ],
   "source": [
    "# Invoke the interpreter. \n",
    "interpreter.invoke() \n",
    "# Get the output. \n",
    "output = interpreter.get_tensor(output_index) \n",
    "print(\"Model output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
